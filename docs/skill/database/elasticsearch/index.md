---
id: elasticsearch-note
slug: /skill/database/elasticsearch
title: elasticsearchç¬”è®°
date: 2021-03-15
tags: [elasticsearch, database]
keywords: [elasticsearch, database]
---

[Elasticsearch Clients | Elastic å®˜æ–¹æ–‡æ¡£](https://www.elastic.co/guide/en/elasticsearch/client/index.html)

## å®‰è£…

ä¸‹è½½åœ°å€:[Elasticsearch, Kibana, and the Elastic Stack | Elastic](https://www.elastic.co/cn/start)

### window

è§£å‹ï¼ŒåŒå‡» bin ç›®å½•ä¸‹çš„ `elasticsearch.bat` å³å¯å¯åŠ¨ï¼Œkibana ä¹Ÿæ˜¯åŒç†ã€‚

å¯åŠ¨åè¾“å…¥ http://localhost:9200 ä¸ http://localhost:5601/ æ˜¾ç¤ºæ­£å¸¸è¯´æ˜ä¸¤è€…éƒ½å®‰è£…æˆåŠŸ

### linux

åŒ windows ä¸è¿‡å¤šå™è¿°äº†

### docker

å½“ç„¶ä¸Šé¢é‚£äº›å®‰è£…éƒ½è¿‡äºéº»çƒ¦ï¼Œdocker ä¸€æ­¥åˆ°ä½

#### elasticsearch

[elasticsearch (docker.com)](https://hub.docker.com/_/elasticsearch)

```
# åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œä¸kibanaé€šä¿¡
docker network create esnet

# æŒ‚è½½ç›®å½• ç«¯å£æ˜ å°„
docker run -d --name elasticsearch --net esnet -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -v /data/elasticsearch:/usr/share/elasticsearch/data -v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins elasticsearch:tag

```

å‚æ•°è¯¦è§£

```text
docker run åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
-d åå°è¿è¡Œ
--name elasticsearch æŒ‡å®šå®¹å™¨å”¯ä¸€çš„åç§°ï¼Œæ–¹ä¾¿ç®¡ç†
-p 9200:9200 -p 9300:9300 æ˜ å°„å®¹å™¨ç«¯å£åˆ°å®¿ä¸»æœºä¸Š
-e "discovery.type=single-node" ç¯å¢ƒå˜é‡é…ç½®å•æœºæ¨¡å¼
-v /data/elasticsearch:/usr/share/elasticsearch/data æŒä¹…åŒ–æ•°æ®å­˜å‚¨
-v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins
elasticsearch:tag é•œåƒåç§°åŠç‰ˆæœ¬ tagæœ€æ–°
```

#### kibana

```
docker run -d --name kibana --net esnet -p 5601:5601 kibana:tag
```

#### ik åˆ†è¯å™¨

```sh
cd /usr/share/elasticsearch/plugins/
elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.2.0/elasticsearch-analysis-ik-7.2.0.zip
exit
docker restart elasticsearch
```

æˆ–

```sh
docker exec -it å®¹å™¨id /bin/bash
cd /usr/share/elasticsearch/plugins/
mkdir ik
cd ik
wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip
yum install unzip
unzip elasticsearch-analysis-ik-7.6.2.zip
exit
docker restart elasticsearch
```

ç„¶åå¯ä»¥åœ¨ kibana ç•Œé¢çš„`dev tools`ä¸­éªŒè¯æ˜¯å¦å®‰è£…æˆåŠŸï¼›

```
POST test/_analyze
{
  "analyzer": "ik_max_word",
  "text": "ä½ å¥½æˆ‘æ˜¯ğŸ“ºå°šå®‡"
}
```

#### è®¾ç½®å¯†ç 

[ElasticSearch è®¾ç½®è´¦æˆ·å¯†ç ](https://blog.csdn.net/qq_43188744/article/details/108096394)

è¿›å…¥ es å®¹å™¨

```
docker exec -it elasticsearch bash

cd config
vi elasticsearch.yml
```

æ·»åŠ å¦‚ä¸‹ä»£ç 

```
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-headers: Authorization
xpack.security.enabled: true
```

é‡å¯å,é‡æ–°è¿›å…¥å®¹å™¨,è¾“å…¥

```
elasticsearch-setup-passwords interactive
```

æŒ‰ y ç¡®è®¤åå³å¯è®¾ç½®å¯†ç 

è¿›å…¥ kibana å®¹å™¨

```
docker exec -it kibana bash

cd config
vi kibana.yml
```

æ·»åŠ å¦‚ä¸‹ä»£ç 

```
elasticsearch.username: "kibana"
elasticsearch.password: "a123456"
```

é¡ºä¾¿åœ¨åŠ è¿™å‡ è¡Œä»£ç ï¼Œåç»­å¦‚æœå¯¼å‡ºæ•°æ®è¿‡å¤§çš„è¯ä¹Ÿå¯¼çš„å‡ºæ¥

```
xpack.reporting.csv.maxSizeBytes: 409715200
xpack.reporting.queue.timeout: 2800000
```

ç™»å½• Kibana çš„è´¦æˆ·å°±æ˜¯ kibana,elasticsearch çš„è´¦æˆ·ä¸º elastic.

## docker-compose

åˆ›å»º volume æŒ‚è½½ç›®å½•ï¼Œå¹¶ä¿®æ”¹ç›®å½•ç”¨æˆ·å’Œç”¨æˆ·ç»„ã€‚ç”±äº elasticsearch6 ä¹‹åä¸å…è®¸ä½¿ç”¨ root å¯ç”¨ï¼Œæ‰€ä»¥éœ€è¦ä¿®æ”¹

```
/usr/share/elasticsearch/dataçš„æƒé™ä¸º1000
mkdir -pv /usr/share/elasticsearch/data
chown 1000:1000 /usr/share/elasticsearch/data
```

éƒ¨ç½²æ–‡ä»¶

```
mkdir /usr/local/elasticsearch-kibana
cd elasticsearch-kibana/
vim docker-compose.yml
```

docker-compose.yml

```yaml
version: '3.9'
services:
  elasticsearch:
    image: elasticsearch:7.2.0
    container_name: elasticsearch
    volumes:
      - /usr/share/elasticsearch/data:/usr/share/elasticsearch/data
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - esnet
    restart: always
  kibana:
    image: kibana:7.2.0
    container_name: kibana
    ports:
      - 5601:5601
    networks:
      - esnet
    depends_on:
      - elasticsearch
    restart: always

networks:
  esnet:
```

vim elasticsearch.yml

```
#é›†ç¾¤å
cluster.name: "elasticsearch"
# å…è®¸å¤–éƒ¨ç½‘ç»œè®¿é—®
network.host: 0.0.0.0
#æ”¯æŒè·¨åŸŸ
http.cors.enabled: true
#æ”¯æŒæ‰€æœ‰åŸŸå
http.cors.allow-origin: "*"
# å¼€å¯xpackå®‰å…¨æ ¡éªŒï¼Œåœ¨kibanaä¸­ä½¿ç”¨éœ€è¦è¾“å…¥è´¦å·å¯†ç 
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true

```

å¯åŠ¨ docker-compose `docker-compose up -d`

è‡³æ­¤æœ‰å…³ elasticSearch å®‰è£…ä¸é…ç½®å°±å‘Šä¸€æ®µè½

## æ•°æ®è¿ç§»

### elasticdump

[elasticsearch-dump/elasticsearch-dump](https://github.com/elasticsearch-dump/elasticsearch-dump)

è¿™é‡Œä½¿ç”¨ elasticdump (å› ä¸ºåªä¼šè¿™ä¸ª)

#### å®‰è£…

```sh
npm install elasticdump -g
elasticdump
```

#### å‘½ä»¤

```
elasticdump --input SOURCE --output DESTINATION [OPTIONS]
```

##### å‚æ•°

- limit

  æ¯ä¸ªæ“ä½œè¦æ‰¹é‡ç§»åŠ¨å¤šå°‘å¯¹è±¡,Limit æ˜¯æ–‡ä»¶æµçš„è¿‘ä¼¼å€¼ é»˜è®¤:100

- type

  å¯¼å‡ºç±»å‹ é»˜è®¤ data [settings, analyzer, data, mapping, policy, alias, template, component_template, index_template]

- å…¶ä»–å‚æ•°çœ‹æ–‡æ¡£,æš‚æ—¶éƒ½ç”¨ä¸ä¸Š

ä¾‹:

```sh
# å°†esæ•°æ®å¯¼å…¥å¦ä¸€å°esæ•°æ®
elasticdump --input=http://production.es.com:9200/my_index --output=http://staging.es.com:9200/my_index --all=true --limit=2000

# æˆ–
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=analyzer
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# å¤‡ä»½æ–‡ä»¶åˆ°æœ¬åœ°
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index_mapping.json \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index.json \
  --type=data

```

#### docker å®‰è£…

```
docker pull elasticdump/elasticsearch-dump
```

ä¾‹:

```
# Copy an index from production to staging with mappings:
docker run --rm -ti elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
docker run --rm -ti elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# Backup index data to a file:
docker run --rm -ti -v /data:/tmp elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=/tmp/my_index_mapping.json \
  --type=data
```

## å¸¸ç”¨å‘½ä»¤

### æŸ¥è¯¢å¹¶åˆ é™¤åŒ¹é…æ–‡æ¡£

æ­£å¸¸æŸ¥è¯¢å¯¹åº”çš„ä»£ç 

```
GET answer/_search
{
  "query": {
    "match_phrase": {
      "topic": "æµ‹è¯•"
    }
  }
}
```

è¦åˆ é™¤ topic ä¸ºâ€œæµ‹è¯•â€ï¼Œåªéœ€è¦å°†`_search`æ›¿æ¢ä¸º`_delete_by_query`å³å¯ã€‚

---

æš‚æ—¶åªç”¨åˆ°è¿™äº› TODOã€‚ã€‚ã€‚

## æ³¨æ„äº‹é¡¹

### elasticsearch é»˜è®¤è¾“å‡ºä¸€ä¸‡æ¡

elasticsearch é»˜è®¤è¾“å‡ºæœ€å¤šä¸€ä¸‡æ¡ï¼ŒæŸ¥è¯¢ç¬¬ 10001 æ¡æ•°æ®å°±ä¼šæŠ¥é”™

è§£å†³æ–¹æ¡ˆ:

1ã€ä¿®æ”¹ elasticsearch è¾“å‡ºé»˜è®¤é™åˆ¶æ¡æ•°

```
PUT ç´¢å¼•åç§°/_settings?preserve_existing=true
{
  "max_result_window": "1000000"
}
```

2ã€åˆ›å»ºç´¢å¼•æ—¶è®¾ç½®

```
"settings":{
    "index":{
        "max_result_window":1000000
 ã€€ã€€}
}
```

3ã€åœ¨è¯·æ±‚çš„æ—¶å€™é™„åŠ å‚æ•°`"track_total_hits":true`

### elasticsearch é»˜è®¤åˆ†é…å†…å®¹ä¸º 1g

elasticsearch é»˜è®¤åˆ†é…å†…å®¹ä¸º 1gï¼Œåœ¨`jvm.options`é…ç½®å¦‚ä¸‹

```
################################################################
## IMPORTANT: JVM heap size
################################################################
##
## The heap size is automatically configured by Elasticsearch
## based on the available memory in your system and the roles
## each node is configured to fulfill. If specifying heap is
## required, it should be done through a file in jvm.options.d,
## and the min and max should be set to the same value. For
## example, to set the heap to 4 GB, create a new file in the
## jvm.options.d directory containing these lines:
##
## -Xms4g
## -Xmx4g
##
## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html
## for more information
##
################################################################

-Xms1g
-Xmx1g
```

å°†å…¶æ›´æ”¹ä¸ºæœåŠ¡å™¨å¯åˆ†é…çš„çš„å†…å­˜ï¼Œæ¯”å¦‚ 32gï¼Œå°±åˆ†é…ä¸ª 16g å³å¯

```
-Xms16g
-Xmx16g
```

é‡å¯ elasticsearch ç”Ÿæ•ˆã€‚

### kibana è®¾ç½®å¯¼å‡º csv å¤§å°

kibana é»˜è®¤å¯¼å‡ºçš„ csv æœ‰æ–‡ä»¶å¤§å°é™åˆ¶ï¼Œé»˜è®¤æ˜¯ 10Mï¼Œæ•°æ®é‡å¤§äº 10Mï¼Œé‚£ä¹ˆ csv åªä¼šä¸‹è½½ 10M å¤§å°çš„æ•°æ®

å¹¶ä¸”å¯¼å‡º CSV æŠ¥å‘Š Kibana æ˜¯æ”¾å…¥é˜Ÿåˆ—ä¸­æ‰§è¡Œçš„ï¼Œæœ‰ä¸€ä¸ªå¤„ç†è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤æ˜¯ 12000 æ¯«ç§’ï¼Œä¹Ÿå°±æ˜¯ 2 åˆ†é’Ÿ

è§£å†³æ–¹æ¡ˆ: é€šè¿‡ä¿®æ”¹é…ç½®å¯ä»¥æ›´æ”¹é™åˆ¶å¤§å°

`vim kibana.yml`

```
# csvæ–‡ä»¶å¤§å°200MB,é»˜è®¤ä¸º10485760ï¼ˆ10MBï¼‰
xpack.reporting.csv.maxSizeBytes: 209715200
# è¶…æ—¶æ—¶é—´-30åˆ†é’Ÿ,é»˜è®¤æ˜¯120000(2åˆ†é’Ÿ)
xpack.reporting.queue.timeout: 1800000
```

**ä¿®æ”¹åï¼Œé‡å¯ kibana å³å¯ç”Ÿæ•ˆ**

> å‚è€ƒ [Kibana 7.X å¯¼å‡º CSV æŠ¥å‘Š](https://blog.csdn.net/qq_25646191/article/details/108641758)

### Kibana server is not ready yet

è®¿é—® Elasticsearch çš„ 9200 ç«¯å£ï¼Œèƒ½æ­£å¸¸è®¿é—®ï¼Œä½†è®¿é—® Kibana çš„ 5601 ç«¯å£å°±æç¤º

```
Kibana server is not ready yet
```

**è§£å†³åŠæ³•**

å°†é…ç½®æ–‡ä»¶ kibana.yml ä¸­çš„ elasticsearch.url æ”¹ä¸ºæ­£ç¡®çš„é“¾æ¥ï¼Œé»˜è®¤ä¸º: http://elasticsearch:9200ï¼Œæ”¹ä¸º http://è‡ªå·±çš„ IP åœ°å€:9200

```
# Default Kibana configuration for docker target
server.name: kibana
server.host: "0"
elasticsearch.hosts: [ "http://elasticsearch:9200" ]
xpack.monitoring.ui.container.elasticsearch.enabled: true
```

ç„¶åé‡å¯ kibana å³å¯ï¼Œè®°å¾—é˜²ç«å¢™å¼€æ”¾ 5601 ç«¯å£

#### å‡ºé—®é¢˜ä¸çŸ¥é“æ€ä¹ˆè§£å†³ï¼ŒæŸ¥çœ‹æ—¥å¿—è¾“å‡ºæ‰æ˜¯å…³é”®

```
docker logs å®¹å™¨id(å®¹å™¨å)
```
